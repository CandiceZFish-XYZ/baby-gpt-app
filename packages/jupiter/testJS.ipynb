{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "%%script node\n",
    "console.log(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[stdin]:1\n",
      "import { Configuration, OpenAIApi } from \"openai\";\n",
      "^^^^^^\n",
      "\n",
      "SyntaxError: Cannot use import statement outside a module\n",
      "    at new Script (node:vm:100:7)\n",
      "    at createScript (node:vm:259:10)\n",
      "    at Object.runInThisContext (node:vm:307:10)\n",
      "    at node:internal/process/execution:79:19\n",
      "    at [stdin]-wrapper:6:22\n",
      "    at evalScript (node:internal/process/execution:78:60)\n",
      "    at node:internal/main/eval_stdin:30:5\n",
      "    at Socket.<anonymous> (node:internal/process/execution:195:5)\n",
      "    at Socket.emit (node:events:525:35)\n",
      "    at endReadableNT (node:internal/streams/readable:1359:12)\n",
      "\n",
      "Node.js v18.14.2\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'import { Configuration, OpenAIApi } from \"openai\";\\nconst configuration = new Configuration({\\n  apiKey: \"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\",\\n});\\nconst openai = new OpenAIApi(configuration);\\n\\nasync function get_completion(prompt, model = \"gpt-3.5-turbo\") {\\n  let messages = [{ role: \"user\", content: prompt }];\\n  let response = await openai.createChatCompletion({\\n    model: model,\\n    messages: messages,\\n    temperature: 0,\\n  });\\n  return response.data.choices[0].message;\\n}\\n\\nconst prompt = \"List three cute cat names.\";\\n\\nlet response = get_completion(prompt);\\nconsole.log(response);\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_cell_magic(\u001b[39m'\u001b[39;49m\u001b[39mscript\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mnode\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mimport \u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m Configuration, OpenAIApi } from \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mopenai\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mconst configuration = new Configuration(\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m  apiKey: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msk-zeYtKIUqRRYMdh1lbDzuT3BlbkFJV2bCxi0FshQ2cWozLgIX\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m});\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mconst openai = new OpenAIApi(configuration);\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39masync function get_completion(prompt, model = \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m) \u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m  let messages = [\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m role: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m, content: prompt }];\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m  let response = await openai.createChatCompletion(\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    model: model,\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    messages: messages,\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    temperature: 0,\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m  });\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m  return response.data.choices[0].message;\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m}\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39mconst prompt = \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mList three cute cat names.\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39mlet response = get_completion(prompt);\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mconsole.log(response);\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2478\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2477\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2478\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2480\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2481\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/IPython/core/magics/script.py:314\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mraise_error \u001b[39mand\u001b[39;00m p\u001b[39m.\u001b[39mreturncode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    310\u001b[0m     \u001b[39m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[39m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     rc \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mreturncode \u001b[39mor\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m9\u001b[39m\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'import { Configuration, OpenAIApi } from \"openai\";\\nconst configuration = new Configuration({\\n  apiKey: \"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\",\\n});\\nconst openai = new OpenAIApi(configuration);\\n\\nasync function get_completion(prompt, model = \"gpt-3.5-turbo\") {\\n  let messages = [{ role: \"user\", content: prompt }];\\n  let response = await openai.createChatCompletion({\\n    model: model,\\n    messages: messages,\\n    temperature: 0,\\n  });\\n  return response.data.choices[0].message;\\n}\\n\\nconst prompt = \"List three cute cat names.\";\\n\\nlet response = get_completion(prompt);\\nconsole.log(response);\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%script node\n",
    "import { Configuration, OpenAIApi } from \"openai\";\n",
    "const configuration = new Configuration({\n",
    "  apiKey: \"sk-\",\n",
    "});\n",
    "const openai = new OpenAIApi(configuration);\n",
    "\n",
    "async function get_completion(prompt, model = \"gpt-3.5-turbo\") {\n",
    "  let messages = [{ role: \"user\", content: prompt }];\n",
    "  let response = await openai.createChatCompletion({\n",
    "    model: model,\n",
    "    messages: messages,\n",
    "    temperature: 0,\n",
    "  });\n",
    "  return response.data.choices[0].message;\n",
    "}\n",
    "\n",
    "const prompt = \"List three cute cat names.\";\n",
    "\n",
    "let response = get_completion(prompt);\n",
    "console.log(response);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
